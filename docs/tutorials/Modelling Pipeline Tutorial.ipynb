{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec8d4c9-f0af-4eeb-a8ff-e3452503f1f9",
   "metadata": {},
   "source": [
    "# Modelling Pipeline (Culling Variant) Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c206473-50f3-469f-be85-7c11ba529286",
   "metadata": {},
   "source": [
    "This tutorial walks through how to run the modeling pipeline which performs \"iterative culling\" of interaction terms based on their p-values after performing LassoCV on initial formulas. It also shows how to potentially add/substitute in main effects into the final formulas obtained from this process in an effort to improve the variance explained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf05fe-9c84-47f1-a66c-4f2b6027b74e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f4dece-1317-4f71-b12d-c5e8ae9045d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.linear_model import LassoCV\n",
    "import warnings\n",
    "import asyncio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata, pearsonr\n",
    "import nest_asyncio\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from patsy import dmatrices, dmatrix\n",
    "\n",
    "from typing import List, Tuple, Any, Dict, Optional\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=matplotlib.MatplotlibDeprecationWarning)\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"The least populated class in y has only\")\n",
    "\n",
    "from yeastdnnexplorer.interface import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd30f9e9-dc7d-4171-806e-2f94d302a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterative_culling import (\n",
    "    create_formulas_with_max_lrb, process_tf_data_combined, find_common_features_across_tfs, filter_significant_features, create_and_fit_combined_filtered_models, get_existing_formulas_and_tfs, evaluate_model, get_cross_validation_folds_from_dataframe, classify_genes, create_max_LRB_columns, custom_wrapper_cross_validation, iterative_model_selection, add_main_effects\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed48c5d1-c40d-41a3-8f5d-fc9987a599a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain data from the DB - a tutorial can be found in the LassoCV notebook\n",
    "all_cc_mcisaac_data = pd.read_csv(\"/Users/ericjia/Downloads/updated_chase_cc_mcisaac_data.csv\")\n",
    "all_tfs = [ \"WTM1\", \"MIG2\", \"RIM101\", \"GZF3\", \"ASH1\", \"TEC1\", \"SIP3\", \"SKN7\", \"WTM2\", \"HAA1\", \"MET31\", \"CRZ1\", \"CHA4\", \"ZAP1\", \"SKO1\", \"FZF1\", \"HAP2\", \"HAP3\", \"HAP5\", \"INO4\", \"RTG1\", \"MOT3\", \"CBF1\", \"MSN2\", \"RTG3\", \"RSF2\", \"HIR2\", \"SIP4\", \"UME1\", \"CIN5\", \"ROX1\", \"XBP1\", \"RDR1\", \"PDR3\", \"RLM1\", \"SFL1\", \"SMP1\", \"PHD1\", \"SUT1\", \"SOK2\", \"STP2\", \"AFT2\", \"YRR1\", \"GAL4\", \"LEU3\", \"SWI6\", \"ACE2\", \"RGM1\", \"GCN4\", \"MIG3\", \"STB5\", \"RFX1\", \"ARG81\", \"AZF1\", \"SFP1\", \"GTS1\", \"FKH1\", \"YOX1\", \"FKH2\", \"DIG1\", \"MET28\", \"RGT1\", ]\n",
    "\n",
    "# ensure that the cc_mcisaac data only include columns for TFs from all_tfs specifically - otherwise the max_LRB calculation has error/noise\n",
    "all_cc_mcisaac_data = all_cc_mcisaac_data[[col for col in all_cc_mcisaac_data.columns if any(substr in col for substr in all_tfs) or col == 'target_locus_tag']]\n",
    "\n",
    "# add the max_LRB terms corresponding to each TF\n",
    "all_cc_mcisaac_data = create_max_LRB_columns(all_cc_mcisaac_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc80dca-7b2c-4554-ac27-520f76bb2757",
   "metadata": {},
   "source": [
    "## LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd77797-4fa1-4893-a373-37367d5ed423",
   "metadata": {},
   "source": [
    "First we create the formulas to be passed into the LASSO regression methods. The formulas take the form:\n",
    "\n",
    "LRR_{tf1} ~ LRB_{tf1} + LRB_{tf1}:LRB_{tf2} + LRB_{tf1}:LRB_{tf3} + ... + max_LRB_{tf1}\n",
    "\n",
    "We are also interested in adding an additional term to the formula called the \"max_LRB\" for each response TF to potentially account for additional variance that can be explained by this term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ddc655-9b0c-4741-ae33-28704a6348bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_formulas = create_formulas_with_max_lrb(all_tfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725179c5-7f07-4a05-996d-55c5108c18cf",
   "metadata": {},
   "source": [
    "Now we call the wrapper method to perform LASSO in both cases and get a dictionary of the surviving features for each response TF. We take the surviving features that appear in both methods moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c76f3704-1b0a-4c33-b550-f3939c40fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = find_common_features_across_tfs(all_tfs, all_cc_mcisaac_data, max_formulas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c404eb5-a12b-4d25-bfb7-a2e4c339bf0e",
   "metadata": {},
   "source": [
    "## Iterative Culling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc1ce2-35a2-4762-a903-73e36d4976f6",
   "metadata": {},
   "source": [
    "Now we perform the culling process which sequentially first performs culling on the entire dataset with p-value threshold 0.001 and cull insignificant terms until all are significant. Then, we repeat the process by using the top10% data by binding, and a less stringent p-value threshold of 0.01 and perform the same culling process until all features are significant. We then keep track of these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f91dea8-faeb-488c-ad83-7a4a1be99379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_models = create_and_fit_combined_filtered_models(common_features, all_cc_mcisaac_data, full_data_iterations=3, top10_data_iterations = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5d963-3ae3-40c6-9f2b-07a9c1e15465",
   "metadata": {},
   "source": [
    "Here is an example of the interaction terms that remain in the formula for the response variable ACE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e0dad8-32fe-454a-890f-2364af6f4065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>LRR_ACE2</td>     <th>  R-squared:         </th> <td>   0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   25.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.90e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:41:15</td>     <th>  Log-Likelihood:    </th> <td> -450.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   662</td>      <th>  AIC:               </th> <td>   914.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   655</td>      <th>  BIC:               </th> <td>   946.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>   -0.0944</td> <td>    0.076</td> <td>   -1.248</td> <td> 0.212</td> <td>   -0.243</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LRB_ACE2:LRB_HAA1</th> <td>   -0.1046</td> <td>    0.027</td> <td>   -3.853</td> <td> 0.000</td> <td>   -0.158</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LRB_ACE2:LRB_SUT1</th> <td>    0.0844</td> <td>    0.029</td> <td>    2.901</td> <td> 0.004</td> <td>    0.027</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LRB_ACE2:LRB_GCN4</th> <td>   -0.1365</td> <td>    0.031</td> <td>   -4.335</td> <td> 0.000</td> <td>   -0.198</td> <td>   -0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LRB_ACE2:LRB_HIR2</th> <td>   -0.1157</td> <td>    0.027</td> <td>   -4.225</td> <td> 0.000</td> <td>   -0.169</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LRB_ACE2</th>          <td>    0.5456</td> <td>    0.058</td> <td>    9.425</td> <td> 0.000</td> <td>    0.432</td> <td>    0.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LRB_ACE2:LRB_GAL4</th> <td>    0.1479</td> <td>    0.030</td> <td>    4.931</td> <td> 0.000</td> <td>    0.089</td> <td>    0.207</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>111.784</td> <th>  Durbin-Watson:     </th> <td>   2.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 186.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.049</td>  <th>  Prob(JB):          </th> <td>3.67e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.532</td>  <th>  Cond. No.          </th> <td>    18.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}      &    LRR\\_ACE2     & \\textbf{  R-squared:         } &     0.189   \\\\\n",
       "\\textbf{Model:}              &       OLS        & \\textbf{  Adj. R-squared:    } &     0.182   \\\\\n",
       "\\textbf{Method:}             &  Least Squares   & \\textbf{  F-statistic:       } &     25.48   \\\\\n",
       "\\textbf{Date:}               & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.90e-27   \\\\\n",
       "\\textbf{Time:}               &     09:41:15     & \\textbf{  Log-Likelihood:    } &   -450.36   \\\\\n",
       "\\textbf{No. Observations:}   &         662      & \\textbf{  AIC:               } &     914.7   \\\\\n",
       "\\textbf{Df Residuals:}       &         655      & \\textbf{  BIC:               } &     946.2   \\\\\n",
       "\\textbf{Df Model:}           &           6      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}    &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                             & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}           &      -0.0944  &        0.076     &    -1.248  &         0.212        &       -0.243    &        0.054     \\\\\n",
       "\\textbf{LRB\\_ACE2:LRB\\_HAA1} &      -0.1046  &        0.027     &    -3.853  &         0.000        &       -0.158    &       -0.051     \\\\\n",
       "\\textbf{LRB\\_ACE2:LRB\\_SUT1} &       0.0844  &        0.029     &     2.901  &         0.004        &        0.027    &        0.142     \\\\\n",
       "\\textbf{LRB\\_ACE2:LRB\\_GCN4} &      -0.1365  &        0.031     &    -4.335  &         0.000        &       -0.198    &       -0.075     \\\\\n",
       "\\textbf{LRB\\_ACE2:LRB\\_HIR2} &      -0.1157  &        0.027     &    -4.225  &         0.000        &       -0.169    &       -0.062     \\\\\n",
       "\\textbf{LRB\\_ACE2}           &       0.5456  &        0.058     &     9.425  &         0.000        &        0.432    &        0.659     \\\\\n",
       "\\textbf{LRB\\_ACE2:LRB\\_GAL4} &       0.1479  &        0.030     &     4.931  &         0.000        &        0.089    &        0.207     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 111.784 & \\textbf{  Durbin-Watson:     } &    2.139  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  186.211  \\\\\n",
       "\\textbf{Skew:}          &   1.049 & \\textbf{  Prob(JB):          } & 3.67e-41  \\\\\n",
       "\\textbf{Kurtosis:}      &   4.532 & \\textbf{  Cond. No.          } &     18.6  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               LRR_ACE2   R-squared:                       0.189\n",
       "Model:                            OLS   Adj. R-squared:                  0.182\n",
       "Method:                 Least Squares   F-statistic:                     25.48\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           2.90e-27\n",
       "Time:                        09:41:15   Log-Likelihood:                -450.36\n",
       "No. Observations:                 662   AIC:                             914.7\n",
       "Df Residuals:                     655   BIC:                             946.2\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept            -0.0944      0.076     -1.248      0.212      -0.243       0.054\n",
       "LRB_ACE2:LRB_HAA1    -0.1046      0.027     -3.853      0.000      -0.158      -0.051\n",
       "LRB_ACE2:LRB_SUT1     0.0844      0.029      2.901      0.004       0.027       0.142\n",
       "LRB_ACE2:LRB_GCN4    -0.1365      0.031     -4.335      0.000      -0.198      -0.075\n",
       "LRB_ACE2:LRB_HIR2    -0.1157      0.027     -4.225      0.000      -0.169      -0.062\n",
       "LRB_ACE2              0.5456      0.058      9.425      0.000       0.432       0.659\n",
       "LRB_ACE2:LRB_GAL4     0.1479      0.030      4.931      0.000       0.089       0.207\n",
       "==============================================================================\n",
       "Omnibus:                      111.784   Durbin-Watson:                   2.139\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              186.211\n",
       "Skew:                           1.049   Prob(JB):                     3.67e-41\n",
       "Kurtosis:                       4.532   Cond. No.                         18.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_models[\"ACE2\"].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec9d27-0ca4-488d-b119-e29012052388",
   "metadata": {},
   "source": [
    "## Experimenting with Main Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbecc05-bafe-48b3-9008-7db6be5bcfba",
   "metadata": {},
   "source": [
    "Now, we might be interested in exploring the potential addition of main effects to our formula in order to improve the variance explained. For each interaction term in our final_models above, we can do the following: 1) modify the formula to replace the interaction term for its corresponding main effect 2) add the main effect into the formula. We can perform CV to determine which formula has the highest average r-squared. If it is one of these modifications that adds/substitutes in a main effect, we can make all changes to the original formula after logging the changes needed across all interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef0252eb-b45f-4f2b-80e8-1bcfa7d25c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = add_main_effects(final_models, all_cc_mcisaac_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d65b7d-282f-4952-b53f-fe7fbda1dd3d",
   "metadata": {},
   "source": [
    "Now, the final results show for each response TF (column 1) the surviving terms from this process (column 2) which are sorted for each response TF by the magnitude of their coefficient in the linear model (column 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d0ec0f-d7d9-4dae-bdf7-6f3571456bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response TF</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACE2</td>\n",
       "      <td>LRB_GAL4</td>\n",
       "      <td>0.215798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACE2</td>\n",
       "      <td>LRB_ACE2</td>\n",
       "      <td>0.145691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACE2</td>\n",
       "      <td>LRB_ACE2:LRB_GCN4</td>\n",
       "      <td>-0.124202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACE2</td>\n",
       "      <td>LRB_ACE2:LRB_SUT1</td>\n",
       "      <td>0.112207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACE2</td>\n",
       "      <td>LRB_SUT1</td>\n",
       "      <td>0.092949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>YOX1</td>\n",
       "      <td>LRB_YOX1:LRB_GZF3</td>\n",
       "      <td>-0.077286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>YOX1</td>\n",
       "      <td>LRB_YOX1:LRB_TEC1</td>\n",
       "      <td>0.009965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ZAP1</td>\n",
       "      <td>LRB_GAL4</td>\n",
       "      <td>0.132575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ZAP1</td>\n",
       "      <td>LRB_ZAP1:LRB_AZF1</td>\n",
       "      <td>-0.093389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ZAP1</td>\n",
       "      <td>LRB_ZAP1:LRB_GAL4</td>\n",
       "      <td>0.081839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Response TF            Feature  Coefficient\n",
       "0          ACE2           LRB_GAL4     0.215798\n",
       "1          ACE2           LRB_ACE2     0.145691\n",
       "2          ACE2  LRB_ACE2:LRB_GCN4    -0.124202\n",
       "3          ACE2  LRB_ACE2:LRB_SUT1     0.112207\n",
       "4          ACE2           LRB_SUT1     0.092949\n",
       "..          ...                ...          ...\n",
       "220        YOX1  LRB_YOX1:LRB_GZF3    -0.077286\n",
       "221        YOX1  LRB_YOX1:LRB_TEC1     0.009965\n",
       "222        ZAP1           LRB_GAL4     0.132575\n",
       "223        ZAP1  LRB_ZAP1:LRB_AZF1    -0.093389\n",
       "224        ZAP1  LRB_ZAP1:LRB_GAL4     0.081839\n",
       "\n",
       "[225 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
