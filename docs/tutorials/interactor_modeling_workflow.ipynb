{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the logger to print to console\n",
    "from typing import Any\n",
    "import logging\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "\n",
    "\n",
    "from yeastdnnexplorer.ml_models.lasso_modeling import (\n",
    "    generate_modeling_data,\n",
    "    stratification_classification,\n",
    "    stratified_cv_modeling,\n",
    "    bootstrap_stratified_cv_modeling,\n",
    "    examine_bootstrap_coefficients,\n",
    "    stratified_cv_r2,\n",
    "    get_interactor_importance,\n",
    "    backwards_OLS_feature_selection,\n",
    "    )\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactor Modeling Workflow 1\n",
    "\n",
    "This tutorial describes a process of modeling perturbation response by binding data\n",
    "with the goal of discovering a meaningful set of interactor terms. More specifically,\n",
    "we start with the following model:\n",
    "\n",
    "$$\n",
    "tf_{perturbed} \\sim tf_{perturbed} + tf_{perturbed}:tf_{2} + tf_{perturbed}:tf_{2} + ... + max(non\\ perturbed\\ binding)\n",
    "$$\n",
    "\n",
    "Where the response variable is the $tf_{perturbed}$ perturbation response, and the\n",
    "predictor variables are binding data (e.g., calling card experiments). Predictor\n",
    "terms such as $tf_{perturbed}:tf_{2}$ represent the interaction between the\n",
    "$tf_{perturbed}$ binding and the binding of another transcription factor. The final\n",
    "term, $\\max(\\text{non-perturbed binding})$, is defined as the maximum binding score\n",
    "for each gene, excluding $tf_{perturbed}$. This term is included to mitigate the\n",
    "effect of outlier genes which may have high binding scores across multiple\n",
    "transcription factors, potentially distorting the model.\n",
    "\n",
    "We assume that the actual relationship between the perturbation response and the\n",
    "binding data is sparse and use the following steps to identify significant terms.\n",
    "These terms represent a set of TFs which, when considered as interactors with the\n",
    "perturbed TF, improve the inferred relationship between the binding and perturbation\n",
    "data.\n",
    "\n",
    "\n",
    "## Interactor sparse modeling\n",
    "\n",
    "1. First, we apply bootstrapping to a 4-fold cross-validated Lasso model. The folds\n",
    "are stratified based on the binding data domain of the perturbed TF, ensuring that\n",
    "each fold better represents the domain structure.\n",
    "\n",
    "    - We produce two variations of this model:\n",
    "        \n",
    "        1. A model trained using all available data.\n",
    "        \n",
    "        2. A model trained using only the top 10% of data based on the binding\n",
    "        score of the perturbed TF.\n",
    "\n",
    "1. For model `1.1`, we select coefficients whose 99.8% confidence interval does not\n",
    "include zero. For model `1.2`, we select coefficients whose 90.0% confidence interval\n",
    "does not include zero. We assume that, due to the non-linear relationship between\n",
    "perturbation response and binding, interaction effects are more pronounced in the\n",
    "top 10% of the data. By intersecting the coefficients from both models, we highlight\n",
    "those that are predictive across the full dataset.\n",
    "\n",
    "1. Now, with our reduced set of features, we perform the exact same process as Step 3 in\n",
    "Workflow 1 above. That is,  With this set of predictors, next create an OLS model using the same 4-fold\n",
    "stratified cross validation from which we calculated an average $R^2$. Next, for each\n",
    "interactor in the model, we produce one other cross validated OLS model by\n",
    "replacing the interactor with its corresponding main effect. We note if this\n",
    "variant yields a better average $R^2$. We remove all features from our set in which the main effect outperforms the interactor term.\n",
    "\n",
    "1. Finally, we report, as significant interactors, the interaction terms which have survived the steps above. We use the average R-squared achieved by this model and compare it to the average R-squared achieved by the univariate counterpart (the response TF predicted solely by its main effect). We would like to create a boxplot of this comparison across all TFs to see how this pipeline affects model performance in explaining variance in contrast to the simple univariate model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE***: To generate the `response_df` and `predictors_df` below, see the first six \n",
    "cells in the LassoCV tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.read_csv(\"~/htcf_local/lasso_bootstrap/erics_tfs/response_dataframe_20241105.csv\", index_col=0)\n",
    "predictors_df = pd.read_csv(\"~/htcf_local/lasso_bootstrap/erics_tfs/predictors_dataframe_20241105.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Find significant predictors using all of the data\n",
    "\n",
    "The function `get_significant_predictors()` is a wrapper of the lassoCV bootstrap \n",
    "protocol described in the LassoCV notebook. It allows using the same code to produce\n",
    "both the 'all data' (step 1.1) and 'top 10%' models (step 1.2), and returns the \n",
    "significant coefficients as described in the protocol above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: the top10% models likely should not have teh same number of classes as the\n",
    "# all data, possibly not stratified at all\n",
    "\n",
    "def get_significant_predictors(\n",
    "    perturbed_tf: str,\n",
    "    response_df: pd.DataFrame,\n",
    "    predictors_df: pd.DataFrame,\n",
    "    add_max_lrb: bool,\n",
    "    **kwargs: Any,\n",
    ") -> tuple[dict[str, tuple[float, float]], pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    This function is used to get the significant predictors for a given TF. It is\n",
    "    capable of conducting steps 1.1 and 1.2 described above.\n",
    "\n",
    "    :param perturbed_tf: the TF for which the significant predictors are to be\n",
    "        identified\n",
    "    :param response_df: The DataFrame containing the response values\n",
    "    :param predictors_df: The DataFrame containing the predictor values\n",
    "    :param add_max_lrb: A boolean to add/not add in the max_LRB term for a response TF\n",
    "        into the formula that we perform bootstrapping on\n",
    "    :param kwargs: Additional arguments to be passed to the function. Expected arguments\n",
    "        are 'quantile_threshold' from generate_modeling_data() and 'ci_percentile' from\n",
    "        examine_bootstrap_coefficients()\n",
    "    :return sig_coef_dict: A dictionary containing the significant predictors and their\n",
    "        corresponding coefficients\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    y, X = generate_modeling_data(\n",
    "        perturbed_tf,\n",
    "        response_df,\n",
    "        predictors_df,\n",
    "        quantile_threshold=kwargs.get(\"quantile_threshold\", None),\n",
    "        drop_intercept=True,\n",
    "    )\n",
    "\n",
    "    # NOTE: fit_intercept is set to `true`\n",
    "    lassoCV_estimator = LassoCV(\n",
    "        fit_intercept=True,\n",
    "        max_iter=10000,\n",
    "        selection=\"random\",\n",
    "        random_state=42,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "\n",
    "    predictor_variable = re.sub(r\"_rep\\d+\", \"\", perturbed_tf)\n",
    "\n",
    "    stratification_classes = stratification_classification(\n",
    "        X[predictor_variable].squeeze(), y.squeeze()\n",
    "    )\n",
    "\n",
    "    # Fit the model to the data in order to extract the alphas_ which are generated\n",
    "    # during the fitting process\n",
    "    lasso_model = stratified_cv_modeling(\n",
    "        y, X, stratification_classes, lassoCV_estimator\n",
    "    )\n",
    "\n",
    "    if add_max_lrb:\n",
    "        # add a column to X which is the rowMax excluding column `predictor_variable`\n",
    "        # called max_lrb\n",
    "        X[\"max_lrb\"] = X.drop(columns=predictor_variable).max(axis=1)\n",
    "\n",
    "    # set the alphas_ attribute of the lassoCV_estimator to the alphas_ attribute of the\n",
    "    # lasso_model fit on the whole data. This will allow the\n",
    "    # bootstrap_stratified_cv_modeling function to use the same set of lambdas\n",
    "    lassoCV_estimator.alphas_ = lasso_model.alphas_\n",
    "\n",
    "    # for test purposes, set n_bootstraps to 10\n",
    "    # NOTE: fit_intercept=True is passed to the internal Lasso model for bootstrap\n",
    "    # iterations, along with some other settings\n",
    "\n",
    "    logging.info(\"running bootstraps\")\n",
    "    bootstrap_lasso_output = bootstrap_stratified_cv_modeling(\n",
    "        y=y,\n",
    "        X=X,\n",
    "        estimator=lassoCV_estimator,\n",
    "        ci_percentile=kwargs.get(\"ci_percentile\", 95.0),\n",
    "        n_bootstraps=kwargs.get(\"n_bootstraps\", 10),\n",
    "        max_iter=10000,\n",
    "        fit_intercept=True,\n",
    "        selection=\"random\",\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    sig_coef_plt, sig_coef_dict = examine_bootstrap_coefficients(\n",
    "        bootstrap_lasso_output, ci_level=kwargs.get(\"ci_percentile\", 95.0)\n",
    "    )\n",
    "\n",
    "    plt.close(sig_coef_plt)\n",
    "\n",
    "    return sig_coef_dict, y, stratification_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant coefficients for 99.8, where intervals are entirely above or below ±0.0:\n",
      "CBF1:SWI6: (-0.14416455697760805, -0.009884405236493745)\n",
      "CBF1:RGM1: (0.014576695345595829, 0.1606224517888866)\n",
      "CBF1:ARG81: (-0.2148742948328769, -0.03345111234665489)\n",
      "CBF1:MET28: (0.07821562304993965, 0.20784574601671207)\n",
      "CBF1:AZF1: (-0.1541657715595909, -0.026421884027885357)\n",
      "CBF1:GAL4: (0.09086284981352442, 0.31851294627923615)\n",
      "CBF1:MSN2: (0.10065808506838021, 0.27766726330427544)\n",
      "max_lrb: (0.0018092836372706894, 0.0983814591861912)\n",
      "Significant coefficients for 90.0, where intervals are entirely above or below ±0.0:\n",
      "CBF1:MET28: (0.06998122210410228, 0.2088974100580522)\n"
     ]
    }
   ],
   "source": [
    "all_data_sig_coef, all_y, all_stratification_classes = get_significant_predictors(\n",
    "    \"CBF1\",\n",
    "    response_df,\n",
    "    predictors_df,\n",
    "    ci_percentile=99.8,\n",
    "    n_bootstraps=100,\n",
    "    add_max_lrb=True)\n",
    "\n",
    "top10_data_sig_coef, top10_y, top10_stratification_classes = get_significant_predictors(\n",
    "    \"CBF1\",\n",
    "    response_df,\n",
    "    predictors_df,\n",
    "    quantile_threshold=0.1,\n",
    "    ci_percentile=90.0,\n",
    "    n_bootstraps=100,\n",
    "    add_max_lrb=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "We next need to intersect the significant coefficients (see definitions above) in both\n",
    "models. In this case, one interactors survives (note that there are only 100\n",
    "bootstraps in this example in the interest of speed for the tutorial. We recommend no \n",
    "less than 1000 in practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The surviving coefficients are: {'CBF1:MET28'}\n"
     ]
    }
   ],
   "source": [
    "intersect_coefficients = set(all_data_sig_coef.keys()).intersection(set(top10_data_sig_coef.keys()))\n",
    "print(f\"The surviving coefficients are: {intersect_coefficients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "We next implement the method which searches alternative models, which include the\n",
    "surviving interactor terms, with variations on substituing in the main effect. In this case, \n",
    "we have a single term. However, if we had more than one term, we would do the following for each surviving interactor term. The goal of this process, remember, is to generate a set of\n",
    "high confidence interactor terms for this TF. If the predictive power of the main effect\n",
    "is equivalent or better than a model with the interactor, we consider that a low\n",
    "confidence interactor effect. \n",
    "\n",
    "After identifying all interactor terms for which substituting in the main effect improves\n",
    "the average R-squared from CV, we drop these terms from our set of features. We then log the final average R-squared achieved by this model. In this case, no terms are dropped from testing the substitution of main effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full model avg r-squared is 0.01051720848723997\n",
      "The interactor results are: []\n",
      "The final model avg r-squared is 0.01051720848723997\n",
      "Final set of terms: {'CBF1:MET28'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericjia/yeastdnnexplorer/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/Users/ericjia/yeastdnnexplorer/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the additional main effects which will be tested from the intersect_coefficients\n",
    "main_effects = []\n",
    "for term in intersect_coefficients:\n",
    "    if \":\" in term:\n",
    "        main_effects.append(term.split(\":\")[1])\n",
    "    else:\n",
    "        main_effects.append(term)\n",
    "\n",
    "# combine these main effects with the intersect_coefficients\n",
    "interactor_terms_and_main_effects = list(intersect_coefficients) + main_effects\n",
    "\n",
    "# generate a model matrix with the intersect terms and the main effects. This full\n",
    "# model will not be used for modeling -- subsets of the columns will be, however.\n",
    "_, full_X = generate_modeling_data(\n",
    "    'CBF1',\n",
    "    response_df,\n",
    "    predictors_df,\n",
    "    formula = f\"~ {' + '.join(interactor_terms_and_main_effects)}\",\n",
    "    drop_intercept=False,\n",
    ")\n",
    "\n",
    "full_X[\"max_lrb\"] = predictors_df.drop(columns=\"CBF1\").max(axis=1)\n",
    "\n",
    "# Currently, this function tests each interactor term in the intersect_coefficients\n",
    "# with two variants by replacing the interaction term with the main effect only, and\n",
    "# with the main effect + interactor. If either of the variants has a higher avg\n",
    "# r-squared than the intersect_model, then that variant is returned. In this case,\n",
    "# the original intersect_coefficients are the best model.\n",
    "full_avg_rsquared, x = get_interactor_importance(\n",
    "    all_y,\n",
    "    full_X,\n",
    "    all_stratification_classes,\n",
    "    intersect_coefficients\n",
    ")\n",
    "\n",
    "print(f\"The full model avg r-squared is {full_avg_rsquared}\")\n",
    "print(f\"The interactor results are: {x}\")\n",
    "\n",
    "# Now that we have identifed the interactors whose main effects improve average R-squared, we drop them from our model\n",
    "\n",
    "if x:\n",
    "    interactors_to_remove = set()\n",
    "    for dictionary in x:\n",
    "        interactor = dictionary.get(\"interactor\")\n",
    "        interactors_to_remove.add(interactor)  \n",
    "        print(\"Removing term: \"+str(interactor))\n",
    "\n",
    "    final_feature_set = intersect_coefficients.difference(interactors_to_remove)\n",
    "    # get the final avg r-squared for this set\n",
    "    final_model_avg_r_squared, _ = get_interactor_importance(\n",
    "        all_y,\n",
    "        full_X,\n",
    "        all_stratification_classes,\n",
    "        final_feature_set\n",
    "    )\n",
    "\n",
    "else:\n",
    "    final_feature_set = intersect_coefficients\n",
    "    final_model_avg_r_squared = full_avg_rsquared\n",
    "\n",
    "print(f\"The final model avg r-squared is {final_model_avg_r_squared}\")\n",
    "print(f\"Final set of terms: {final_feature_set}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Comparing our final model to a univariate model\n",
    "\n",
    "In our last step, we take our reamining set of features from the end of Step 3, and now compare its performance to that of a univariate model where the response TF is predicted solely by its main effect. We will use the average R-squared achieved by 4-Fold CV on both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The univariate average R-squared is: 0.004970412632932103\n",
      "The final model average R-squared is 0.01051720848723997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericjia/yeastdnnexplorer/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y, X = generate_modeling_data(\"CBF1\", response_df, predictors_df, drop_intercept=True, formula=\"CBF1_LRR ~ CBF1\")\n",
    "classes = stratification_classification(X[\"CBF1\"].squeeze(), y.squeeze())\n",
    "avg_r2_univariate = stratified_cv_r2(\n",
    "        y,\n",
    "        X,  \n",
    "        classes,\n",
    "    )\n",
    "\n",
    "print(f\"The univariate average R-squared is: {avg_r2_univariate}\")\n",
    "print(f\"The final model average R-squared is {final_model_avg_r_squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the final model we achieved through Workflow 1 demonstrates a higher average R-squared achieved by 4-fold CV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactor Modeling Workflow 2\n",
    "\n",
    "An alternative workflow to identifying a meaningful set of transcription factors takes a slightly different approach. There are some commonalities between this workflow and Workflow 1, and we will point them out in the steps below which outline how this alternative workflow operates.\n",
    "\n",
    "\n",
    "1. First, we apply a 4-fold cross-validated Lasso model (without bootstrapping - this is the \n",
    "difference between this step and Step 1 from Workflow 1). The folds\n",
    "are stratified based on the binding data domain of the perturbed TF, ensuring that\n",
    "each fold better represents the domain structure.\n",
    "\n",
    "    - We produce two variations of this model:\n",
    "        \n",
    "        1. A model trained using all available data.\n",
    "        \n",
    "        2. A model trained using only the top 10% of data based on the binding\n",
    "        score of the perturbed TF.\n",
    "\n",
    "2. Each Lasso model from Step 1 will return a set of non-zero coefficients. We then intersect the coefficients from both models, and retain this list of features\n",
    "in the exact same fashion as Step 2 of Workflow 1.  \n",
    "\n",
    "3. With this set of predictors, we then perform a \"backwards OLS feature selection,\" in \n",
    "which we create OLS models using this set of predictors on the entire dataset, and remove\n",
    "features which have a p-value above a threshold for significance (0.001). We continously \n",
    "remove features and re-create models on the reduced set of features until all of the \n",
    "features in a model are significant. Then, taking this filtered set of predictors, we \n",
    "perform the same process, but this time on the top 10% of the data based on the binding\n",
    "score of the perturbed TF. Since we are now using a smaller dataset, our threshold for \n",
    "significance is increased (0.01), and we perform the same process until we arrive at a \n",
    "final model in which all of the terms are significant. \n",
    "\n",
    "From here onwards, we follow the same steps as Step 3 and Step 4 in Workflow 1 above. I have copied their descriptions from above, and have renamed them Steps 4 and 5 to match the numbering for this workflow.\n",
    "\n",
    "4. Now, with our reduced set of features, we perform the exact same process as Step 3 in\n",
    "Workflow 1 above. That is,  With this set of predictors, next create an OLS model using the same 4-fold\n",
    "stratified cross validation from which we calculated an average $R^2$. Next, for each\n",
    "interactor in the model, we produce one other cross validated OLS model by\n",
    "replacing the interactor with its corresponding main effect. We note if this\n",
    "variant yields a better average $R^2$. We remove all features from our set in which the main effect outperforms the interactor term.\n",
    "\n",
    "5. Finally, we report, as significant interactors, the interaction terms which have survived the steps above. We use the average R-squared achieved by this model and compare it to the average R-squared achieved by the univariate counterpart (the response TF predicted solely by its main effect). We would like to create a boxplot of this comparison across all TFs to see how this pipeline affects model performance in explaining variance in contrast to the simple univariate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose a particular TF to run though this workflow with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_of_interest = \"CBF1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: get the non-zero coefficients from the Lasso models\n",
    "\n",
    "The function `get_non_zero_predictors()` is a wrapper of the stratified CV modeling \n",
    "protocol described in the LassoCV notebook. It allows using the same code to produce\n",
    "the Lasso models trained on the 'all data' (step 1.1) and 'top 10%' models (step 1.2), and returns the \n",
    "features with non-zero coefficients as described in the protocol above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_non_zero_predictors(\n",
    "    perturbed_tf: str,\n",
    "    response_df: pd.DataFrame,\n",
    "    predictors_df: pd.DataFrame,\n",
    "    **kwargs: Any,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    This function is used to get the features with non-zero coefficients from LassoCV\n",
    "    for a given TF. It is capable of conducting steps 1a and 1b above.\n",
    "\n",
    "    :param perturbed_tf: str, the TF for which the significant predictors are to be\n",
    "        identified\n",
    "    :param response_df: pd.DataFrame, the response dataframe containing the response\n",
    "        values\n",
    "    :param predictors_df: pd.DataFrame, the predictors dataframe containing the\n",
    "        predictor values\n",
    "    :param kwargs: dict, additional arguments to be passed to the function. Expected\n",
    "        arguments is 'quantile_threshold' fom generate_modeling_data() to signify the\n",
    "        top 10%\n",
    "    :return non_zero_features: List, a list containing the features with non-zero coefs\n",
    "\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if perturbed_tf not in response_df.columns:\n",
    "        raise ValueError(\n",
    "            f\"The response TF {perturbed_tf} does not exist in the response DataFrame.\"\n",
    "        )\n",
    "    if perturbed_tf not in predictors_df.columns:\n",
    "        raise ValueError(\n",
    "            f\"The response TF {perturbed_tf} does not exist in the binding DataFrame.\"\n",
    "        )\n",
    "    if response_df.shape[0] != predictors_df.shape[0]:\n",
    "        raise ValueError(\n",
    "            \"The binding and response DataFrames contain different counts of genes\"\n",
    "        )\n",
    "\n",
    "    tf_y, tf_X = generate_modeling_data(\n",
    "        perturbed_tf,\n",
    "        response_df,\n",
    "        predictors_df,\n",
    "        quantile_threshold=kwargs.get(\"quantile_threshold\", None),\n",
    "        drop_intercept=True,\n",
    "    )\n",
    "\n",
    "    # add the max_lrb term to the formula\n",
    "    tf_X[\"max_lrb\"] = predictors_df.drop(columns=perturbed_tf).max(axis=1)\n",
    "\n",
    "    # NOTE: fit_intercept is set to `true`\n",
    "    lassoCV_estimator = LassoCV(\n",
    "        fit_intercept=True,\n",
    "        max_iter=10000,\n",
    "        selection=\"random\",\n",
    "        random_state=42,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "\n",
    "    # create the classifications\n",
    "    classes = stratification_classification(tf_X[perturbed_tf], tf_y[perturbed_tf])\n",
    "\n",
    "    # Fit the model to the data in order to extract the non-zero coefficients\n",
    "    # surviving after the fitting process\n",
    "    lasso_model = stratified_cv_modeling(tf_y, tf_X, classes, lassoCV_estimator)\n",
    "\n",
    "    # return a list of the non-zero features that survived the fitting\n",
    "    non_zero_indices = lasso_model.coef_ != 0\n",
    "    non_zero_features = tf_X.columns[non_zero_indices]\n",
    "\n",
    "    return non_zero_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: get the non-zero features on all data\n",
    "tf_surviving_terms = get_non_zero_predictors(tf_of_interest, response_df, predictors_df)\n",
    "# Step 1.2: get the non-zero features on only the top10% of genes\n",
    "tf_top10_surviving_terms = get_non_zero_predictors(tf_of_interest, response_df, predictors_df, quantile_threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Intersect the features from both Lasso models\n",
    "\n",
    "Here, we simply intersect the sets of non-zero features found by both of the Lasso models in Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The surviving coefficients are: {'CBF1:SWI6', 'CBF1:SKN7', 'CBF1:AZF1', 'CBF1:MET28'}\n"
     ]
    }
   ],
   "source": [
    "intersect_coefficients = set(tf_surviving_terms).intersection(set(tf_top10_surviving_terms))\n",
    "print(f\"The surviving coefficients are: {intersect_coefficients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Perform backwards OLS feature selection on the intersected features\n",
    "\n",
    "Now, taking our set of intersecting features from the step above, we perform the process of backwards OLS feature selection as described above. The function `backwards_OLS_feature_selection()` is a wrapper function that repeatedly calls `select_significant_features()` to perform the iterative process of removing insignificant features based on their p-value with respect to the given quantile threshold. Currently, we are performing this both on the entire dataset with a p-value threshold of 0.001, then subsequently on the top 10% by perturbed TF binding data with a p-value threshold of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The surviving features from backwards OLS feature selection is {'CBF1:MET28', 'CBF1:SWI6'}\n"
     ]
    }
   ],
   "source": [
    "quantile_thresholds = [None, 0.1]  # None for full dataset, 0.1 for top 10%\n",
    "p_value_thresholds = [0.001, 0.01]  # Corresponding p-value thresholds for both datasets\n",
    "\n",
    "backward_OLS_feature_result = backwards_OLS_feature_selection(\n",
    "    tf_of_interest,\n",
    "    intersect_coefficients,\n",
    "    response_df,\n",
    "    predictors_df,\n",
    "    quantile_thresholds,\n",
    "    p_value_thresholds,\n",
    ")\n",
    "\n",
    "print(f\"The surviving features from backwards OLS feature selection is {backward_OLS_feature_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "This is now the exact same workflow as Step 3 from Workflow 1. To recap, we now implement the method which searches alternative models, which include the surviving interactor terms, with variations on including the main effect. The goal of this process is to generate a set of high confidence interactor terms for this TF. If the predictive power of the main effect is equivalent or better than a model with the interactor, we consider that a low confidence interactor effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericjia/yeastdnnexplorer/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/Users/ericjia/yeastdnnexplorer/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/Users/ericjia/yeastdnnexplorer/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full model avg r-squared is 0.016951766474153418\n",
      "The interactor results are: []\n",
      "The final model avg r-squared is 0.016951766474153418\n",
      "Final set of terms: {'CBF1:MET28', 'CBF1:SWI6'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the additional main effects which will be tested from the backward_OLS_feature_result\n",
    "main_effects = []\n",
    "for term in backward_OLS_feature_result:\n",
    "    if \":\" in term:\n",
    "        main_effects.append(term.split(\":\")[1])\n",
    "    else:\n",
    "        main_effects.append(term)\n",
    "\n",
    "# combine these main effects with the backward_OLS_feature_result\n",
    "interactor_terms_and_main_effects = list(backward_OLS_feature_result) + main_effects\n",
    "\n",
    "# generate a model matrix with the intersect terms and the main effects. This full\n",
    "# model will not be used for modeling -- subsets of the columns will be, however.\n",
    "_, full_X = generate_modeling_data(\n",
    "    tf_of_interest,\n",
    "    response_df,\n",
    "    predictors_df,\n",
    "    formula = f\"~ {' + '.join(interactor_terms_and_main_effects)}\",\n",
    "    drop_intercept=False\n",
    ")\n",
    "\n",
    "# have to generate the stratification classes and the \"y\" column for input into \n",
    "# get_interactor_importance below\n",
    "y, X = generate_modeling_data(tf_of_interest, response_df, predictors_df)\n",
    "all_stratification_classes = stratification_classification(X[tf_of_interest].squeeze(), y.squeeze())\n",
    "\n",
    "# Currently, this function tests each interactor term in the backward_OLS_feature_result\n",
    "# with two variants by replacing the interaction term with the main effect only, and\n",
    "# with the main effect + interactor. If either of the variants has a higher avg\n",
    "# r-squared than the intersect_model, then that variant is returned. \n",
    "full_avg_rsquared, x = get_interactor_importance(\n",
    "    y,\n",
    "    full_X,\n",
    "    all_stratification_classes,\n",
    "    backward_OLS_feature_result\n",
    ")\n",
    "\n",
    "print(f\"The full model avg r-squared is {full_avg_rsquared}\")\n",
    "print(f\"The interactor results are: {x}\")\n",
    "\n",
    "if x:\n",
    "    interactors_to_remove = set()\n",
    "    for dictionary in x:\n",
    "        interactor = dictionary.get(\"interactor\")\n",
    "        interactors_to_remove.add(interactor)  \n",
    "        print(f\"Removing term: {interactor}\")\n",
    "\n",
    "    final_feature_set = backward_OLS_feature_result.difference(interactors_to_remove)\n",
    "    # get the final avg r-squared for this set\n",
    "    final_model_avg_r_squared, _ = get_interactor_importance(\n",
    "        y,\n",
    "        full_X,\n",
    "        all_stratification_classes,\n",
    "        final_feature_set\n",
    "    )\n",
    "\n",
    "else:\n",
    "    final_feature_set = backward_OLS_feature_result\n",
    "    final_model_avg_r_squared = full_avg_rsquared\n",
    "\n",
    "print(f\"The final model avg r-squared is {final_model_avg_r_squared}\")\n",
    "print(f\"Final set of terms: {final_feature_set}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "This is the same as Step 4 from Workflow 1 above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The univariate average R-squared is: 0.004970412632932103\n",
      "The final model average R-squared is 0.016951766474153418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericjia/yeastdnnexplorer/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y, X = generate_modeling_data(tf_of_interest, response_df, predictors_df, drop_intercept=True, formula=f\"{tf_of_interest}_LRR ~ {tf_of_interest}\")\n",
    "avg_r2_univariate = stratified_cv_r2(\n",
    "        y,\n",
    "        X,  \n",
    "        all_stratification_classes,\n",
    "    )\n",
    "\n",
    "print(f\"The univariate average R-squared is: {avg_r2_univariate}\")\n",
    "print(f\"The final model average R-squared is {final_model_avg_r_squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the final mdel we achieved through Workflow 2 demonstrates a higher average R-squared achieved by 4-fold CV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
